# âœˆï¸ Aircraft Damage Classification (Crack vs Dent) & ğŸ–¼ï¸ Image Caption Generation  

This repository contains my **Final Project** for the course:  
**â€œIntroduction to Deep Learning & Neural Networks with Kerasâ€**  

The project has **two major components**:  

1. **Aircraft Damage Classification** â€“ A **Convolutional Neural Network (CNN)** with **Transfer Learning (VGG16)** to classify aircraft damages into **Cracks vs. Dents**.  
2. **Image Caption Generation** â€“ Using **BLIP (Bootstrapping Language-Image Pretraining)** to generate meaningful captions for images.  

---

## ğŸ“Œ Project Overview  

- âœ… Built and trained a CNN for **aircraft damage classification** with **>81% test accuracy**.  
- âœ… Classified **type of damage (Crack / Dent)** instead of just binary damaged vs. normal.  
- âœ… Applied **Transfer Learning (VGG16)** with **data augmentation** and **callbacks** (EarlyStopping, ReduceLROnPlateau).  
- âœ… Implemented **BLIP** for **image captioning** that generates human-like captions.  
- âœ… Explored both **computer vision (classification)** and **vision-language (captioning)** tasks in one project.  

---

## ğŸ› ï¸ Tech Stack  

- **Frameworks:** TensorFlow, Keras, PyTorch  
- **Models:** CNN, VGG16 (Transfer Learning), BLIP  
- **Languages:** Python  
- **Tools:** Jupyter Notebook, Google Colab  

---

## ğŸ“‚ Project Structure  

<pre>
  
â”œâ”€â”€aircraft_damage_dataset_v1/
|  â”œâ”€â”€ train/
|  â”‚   â”œâ”€â”€ dent/
|  â”‚   â””â”€â”€ crack/
|  â”œâ”€â”€ valid/
|  â”‚   â”œâ”€â”€ dent/
|  â”‚   â””â”€â”€ crack/
|  â””â”€â”€ test/
|      â”œâ”€â”€ dent/
|      â””â”€â”€ crack/ 
â”œâ”€â”€ aircraft_damage_dataset_v1.tar
â”œâ”€â”€ Damage_Detection_and_BLIP_Captioning # BLIP caption generation
â”œâ”€â”€ download_dataset.py                  # Download the dataset
â”œâ”€â”€ requirements.txt                     # Required dependencies
â”œâ”€â”€ .gitignore                           # Avoid venv and dataset
â””â”€â”€ README.md                            # Project documentation
  
</pre>

---

## âš¡ How to Run  

1. Clone this repo:  
   ```bash
   git clone https://github.com/your-username/aircraft-damage-and-captioning.git
   cd aircraft-damage-and-captioning

2. Install dependencies:
   ```bash
   pip install -r requirements.txt

3. Download the dataset:
   ```bash
   python download_dataset.py

4. Run the Jupyter notebook:

- Damage_Detection_and_BLIP_Captioning.ipynb

---

## ğŸš€ Results  

### Aircraft Damage Classification (Crack vs Dent)  
- **Training Accuracy:** ~85%  
- **Test Accuracy:** ~81%  
- **Model Used:** VGG16 (frozen base + fine-tuned dense layers)    

ğŸ“Š Example:  

| Image | Prediction |
|-------|------------|
| ![crack](sample_images/crack.jpg) | Crack |
| ![dent](sample_images/dent.jpg)   | Dent |

---

### Image Caption Generation (BLIP)  

BLIP generates captions for unseen images:  

- Input: ğŸ–¼ï¸ *Aircraft flying in cloudy sky*  
- Output: **"an airplane flying through the clouds"**  

- Input: ğŸ–¼ï¸ *Damaged aircraft*  
- Output: **"a damaged airplane parked on the runway"**  

---

## ğŸ“œ Certificate  

This project was submitted as part of my completion for **Introduction to Deep Learning & Neural Networks with Keras (IBM)**.  
ğŸ“ Certificate available here â†’ [Add your certificate image/link]  

---

## ğŸ™Œ Acknowledgements

- IBM: Introduction to Deep Learning & Neural Networks with Keras
- OpenAI BLIP Model
= Aircraft damage dataset (publicly available)
   
